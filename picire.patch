diff --git a/src/picire/picire/VERSION b/src/picire/picire/VERSION
new file mode 100644
index 00000000..d5908b99
--- /dev/null
+++ b/src/picire/picire/VERSION
@@ -0,0 +1 @@
+20.12
\ No newline at end of file
diff --git a/src/picire/picire/abstract_cdd.py b/src/picire/picire/abstract_cdd.py
new file mode 100644
index 00000000..1d3ad27c
--- /dev/null
+++ b/src/picire/picire/abstract_cdd.py
@@ -0,0 +1,284 @@
+# Copyright (c) 2016-2020 Renata Hodovan, Akos Kiss.
+#
+# Licensed under the BSD 3-Clause License
+# <LICENSE.rst or https://opensource.org/licenses/BSD-3-Clause>.
+# This file may not be copied, modified, or distributed except
+# according to those terms.
+
+import logging
+import collections
+import time
+import math
+import sys
+import copy
+from . import utils
+from datetime import datetime
+
+logger = logging.getLogger(__name__)
+
+
+class AbstractCDD(object):
+    """
+    Abstract super-class of the CDD class.
+    """
+
+    # Test outcomes.
+    PASS = 'PASS'
+    FAIL = 'FAIL'
+
+    def __init__(self, test, split, id_prefix=(), other_config={}):
+        self._test = test
+        self._split = split
+        self._id_prefix = id_prefix
+        self.init_probability = other_config["init_probability"]
+        self.dd = other_config["dd"]
+        self.threshold = 0.8
+
+    def __call__(self, config):
+        
+        tstart = time.time()
+        self.original_config = config[:]
+
+        # initialize based on the specificed sample startegy
+        if (self.dd == "cdd"):
+            # initialize counters
+            self.counters = [0 for _ in range(len(config))]
+            self.sample = self.sample_by_counter
+            self.update_when_fail = self.update_when_fail_cdd
+            self.update_when_success = self.update_when_success_cdd
+            self._test_done = self._test_done_cdd
+
+        elif (self.dd == "probdd"):
+            # initialize probabilities
+            self.probabilities = [self.init_probability for _ in range(len(config))]
+            self.sample = self.sample_by_probability
+            self.update_when_fail = self.update_when_fail_probdd
+            self.update_when_success = self.update_when_success_probdd
+            self._test_done = self._test_done_probdd
+
+        else:
+            raise ValueError("dd should be either cdd or probdd")
+
+        # initialize current best config idx, all true
+        self.current_best_config_idx = [True for _ in range(len(config))]
+        
+        run = 0
+        while not self._test_done():
+            logger.info('Run #%d', run)
+            logger.info('\tConfig size: %d', self.get_current_config_size())
+            
+            # select a subsequence for testing
+            config_idx_to_delete = self.sample()
+            log_to_print = utils.generate_log(config_idx_to_delete, "Try deleting", print_idx=True, threshold=30)
+            logger.info(log_to_print)
+            config_log_id = ('r%d' % run, )
+
+            outcome = self._test_config(config_idx_to_delete, config_log_id)
+            # FAIL means current variant cannot satisify the property
+            
+            # if the subset cannot be deleted
+            if (outcome == self.FAIL):
+                self.update_when_fail(config_idx_to_delete)
+            
+            # if the subset can be deleted
+            else:
+                self.update_when_success(config_idx_to_delete)
+                log_to_print = utils.generate_log(config_idx_to_delete, "Deleted", print_idx=True, threshold=30)
+                logger.info(log_to_print)
+            
+            run += 1
+
+        logger.info("Final size: %d/%d" % (self.get_current_config_size(), len(config)))
+        logger.info("Execution time at this level: %f s" % (time.time() - tstart))
+        return self.map_idx_to_config(self.current_best_config_idx)
+    
+    def get_current_config_size(self):
+        return sum(self.current_best_config_idx)
+
+    def _processElementToPreserve(toBePreserve):
+        raise NotImplementedError()
+
+    def _process(self, config, outcome):
+        raise NotImplementedError()
+    
+    # directly compute the size of next subset based on the counter
+    def compute_size(self, counter):
+        size = round(-1 / math.log(1 - self.init_probability, math.e))
+        i = 0
+        while i < counter:
+            logger.info("i=%d, counter=%d, size=%d" % (i, counter, size))
+            size = math.floor(size * (1 - pow(math.e, -1)))
+            i = i + 1
+        size = min(size, len(self.counters))
+        size = max(size, 1)
+        return size
+
+    # increase all counters by 1
+    def increase_all_counters(self):
+        for idx in range(len(self.counters)):
+            if (self.counters[idx] != -1):
+                self.counters[idx] = self.counters[idx] + 1
+
+    # find out the minimal counter among all available elements
+    def find_min_counter(self):
+        current_min = sys.maxsize
+        for counter in self.counters:
+            if (counter != -1 and current_min > counter):
+                current_min = counter
+        return current_min
+    
+    # how cdd compute the next subset to delete
+    def sample_by_counter(self):
+        
+        # filter out those removed elements (counter is -1)
+        available_idx_with_counter = [(idx, counter) for idx, counter in enumerate(self.counters) if counter != -1]
+
+        # sort idx by counter
+        sorted_available_idx_with_counter = sorted(available_idx_with_counter, key=lambda x: x[1])
+
+        # extract sorted idx
+        sorted_available_idx = [idx for idx, _ in sorted_available_idx_with_counter]
+
+        counter_min = self.find_min_counter()
+        current_size = self.compute_size(counter_min)
+        current_config_size = self.get_current_config_size()
+        
+        while current_size >= current_config_size:
+            self.increase_all_counters()
+            counter_min = self.find_min_counter()
+            current_size = self.compute_size(counter_min)
+            if (current_size == 1):
+                break
+
+        config_idx_to_delete = sorted_available_idx[:current_size]
+        logger.info("\tSelected deletion size (cdd): " + str(len(config_idx_to_delete)))
+        return config_idx_to_delete
+    
+    # how probdd compute the next subset to delete
+    def sample_by_probability(self):
+
+        # filter out those removed elements (probability is -1)
+        available_idx_with_probability = [(idx, probability) for idx, probability in enumerate(self.probabilities) if probability != -1]
+
+        # sort idx by probability
+        sorted_available_idx_with_probability = sorted(available_idx_with_probability, key=lambda x: x[1])
+
+        # extract sorted idx
+        sorted_available_idx = [idx for idx, _ in sorted_available_idx_with_probability]
+
+        current_size = 0
+        accumulated_probability = 1
+        current_gain = 1
+        last_gain = 0
+        while current_size < len(sorted_available_idx):
+            current_size = current_size + 1
+
+            current_idx = sorted_available_idx[current_size - 1]
+            accumulated_probability = accumulated_probability * (1 - self.probabilities[current_idx])
+
+            current_gain = accumulated_probability * current_size
+
+            # find out the size with max gain and stop
+            if (current_gain < last_gain):
+                break
+            last_gain = current_gain
+
+        config_idx_to_delete = sorted_available_idx[:current_size]
+
+        logger.info("\tSelected deletion size (probdd): " + str(len(config_idx_to_delete)))
+        return config_idx_to_delete
+
+    # Given a subset failed to be deleted,
+    # compute the ratio to increase the probability of each element in this subset
+    def compute_ratio(self, config_idx_to_delete):
+        accumulated_probability = 1
+        for idx in config_idx_to_delete:
+            accumulated_probability = accumulated_probability * (1 - self.probabilities[idx])
+
+        ratio = 1 / (1 - accumulated_probability)
+        return ratio
+
+    def update_when_fail_cdd(self, config_idx_to_delete):
+        for idx in config_idx_to_delete:
+            self.counters[idx] = self.counters[idx] + 1
+        if (len(config_idx_to_delete) == 1):
+            # assign the counter to maxsize and never consider this element
+            self.counters[config_idx_to_delete[0]] = -1
+
+    def update_when_fail_probdd(self, config_idx_to_delete):
+        ratio = self.compute_ratio(config_idx_to_delete)
+
+        for idx in config_idx_to_delete:
+            self.probabilities[idx] = self.probabilities[idx] * ratio
+            if (self.probabilities[idx] > self.threshold):
+                self.probabilities[idx] = -1
+
+        if (len(config_idx_to_delete) == 1):
+            # never consider this element
+            self.probabilities[config_idx_to_delete[0]] = -1
+
+    def update_when_success_cdd(self, config_idx_to_delete):
+        for idx in config_idx_to_delete:
+            self.counters[idx] = -1
+            self.current_best_config_idx[idx] = False
+
+    def update_when_success_probdd(self, config_idx_to_delete):
+        for idx in config_idx_to_delete:
+            self.probabilities[idx] = -1
+            self.current_best_config_idx[idx] = False
+
+    def _test_done_cdd(self):
+        all_decided = True
+        for counter in self.counters:
+            if (counter != -1):
+                all_decided = False
+        if (all_decided == True):
+            logger.info("Iteration needs to stop because all elements are decided.")
+            return True
+        else:
+            return False
+        
+    def _test_done_probdd(self):
+        all_decided = True
+        for probability in self.probabilities:
+            if (probability != -1):
+                all_decided = False
+        if (all_decided == True):
+            logger.info("Iteration needs to stop because all elements are decided.")
+            return True
+        else:
+            return False
+
+    def map_idx_to_config(self, config_idx):
+        new_config = []
+        for idx, availability in enumerate(config_idx):
+            if (availability == True):
+                new_config.append(self.original_config[idx])
+        
+        return new_config
+
+    def _test_config(self, config_idx_to_delete, config_log_id):
+        config_log_id = self._id_prefix + config_log_id
+        logger.debug('\t[ %s ]: test...', self._pretty_config_id(config_log_id))
+
+        # compute new config idx
+        logger.info("before deep copy")
+        new_config_idx = self.current_best_config_idx[:]
+        logger.info("after deep copy")
+        for idx in config_idx_to_delete:
+            new_config_idx[idx] = False
+        logger.info("exclude elements in config_idx_to_delete")
+
+        new_config = self.map_idx_to_config(new_config_idx)
+        logger.info("after mapping")
+        tstart = time.time()
+        outcome = self._test(new_config, config_log_id)
+        logger.info("execution time of this test: " + str(time.time() - tstart) + "s")
+
+        logger.debug('\t[ %s ]: test = %r', self._pretty_config_id(config_log_id), outcome)
+
+        return outcome
+
+    @staticmethod
+    def _pretty_config_id(config_id):
+        return ' / '.join(str(i) for i in config_id)
\ No newline at end of file
diff --git a/src/picire/picire/abstract_dd.py b/src/picire/picire/abstract_dd.py
index c7780139..680d242a 100644
--- a/src/picire/picire/abstract_dd.py
+++ b/src/picire/picire/abstract_dd.py
@@ -7,11 +7,18 @@
 
 import itertools
 import logging
+import random
+import time
 
 from .outcome_cache import OutcomeCache
 
 logger = logging.getLogger(__name__)
 
+def split_list(input_list, chunk_size):
+    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]
+
+def flatten(l):
+    return [item for sublist in l for item in sublist]
 
 class AbstractDD(object):
     """
@@ -22,7 +29,7 @@ class AbstractDD(object):
     PASS = 'PASS'
     FAIL = 'FAIL'
 
-    def __init__(self, test, split, cache=None, id_prefix=()):
+    def __init__(self, test, split, cache=None, id_prefix=(), other_config={}):
         """
         Initialise an abstract DD class. Not to be called directly, only by
         super calls in subclass initializers.
@@ -36,28 +43,41 @@ class AbstractDD(object):
         self._split = split
         self._cache = cache or OutcomeCache()
         self._id_prefix = id_prefix
+        self.onepass = other_config["onepass"]
+        self.start_from_n = other_config["start_from_n"]
+        self.delete_history = []
+
 
-    def ddmin(self, config):
+    def __call__(self, config):
         """
         Return a 1-minimal failing subset of the initial configuration.
 
         :param config: The initial configuration that will be reduced.
         :return: 1-minimal failing configuration.
         """
-        subsets = [config]
+        #print("enter picire/abstract_dd.py:__call__()")
+        self.original_config = config[:]
+        self.original_config_size = len(self.original_config)
+        self.original_config_idx = list(range(self.original_config_size))
+        current_config_idx = self.original_config_idx[:]
+        if (self.start_from_n):
+            subsets = split_list(self.original_config_idx, self.start_from_n)
+        else:
+            subsets = [self.original_config_idx]
         complement_offset = 0
 
         for run in itertools.count():
             logger.info('Run #%d', run)
-            logger.info('\tConfig size: %d', len(config))
-            assert self._test_config(config, ('r%d' % run, 'assert')) == self.FAIL
+            logger.info('\tConfig size: %d', len(current_config_idx))
+            #assert self._test_config(config, ('r%d' % run, 'assert')) == self.FAIL
 
             # Minimization ends if the configuration is already reduced to a single unit.
-            if len(config) < 2:
+            if len(current_config_idx) < 2:
                 logger.info('\tGranularity: %d', len(subsets))
                 logger.debug('\tConfig: %r', subsets)
+                logger.info("\t Final result: %d/%d" % (len(flatten(subsets)), self.original_config_size))
                 logger.info('\tDone')
-                return config
+                return self.idx2config(current_config_idx)
 
             if len(subsets) < 2:
                 assert len(subsets) == 1
@@ -71,11 +91,11 @@ class AbstractDD(object):
             if next_subsets is not None:
                 # Interesting configuration is found, start new iteration.
                 subsets = next_subsets
-                config = [c for s in subsets for c in s]
+                current_config_idx = [c for s in subsets for c in s]
 
-                logger.info('\tReduced')
+                #logger.info('\tReduced')
 
-            elif len(subsets) < len(config):
+            elif len(subsets) < len(current_config_idx):
                 # No interesting configuration is found but it is still not the finest splitting, start new iteration.
                 next_subsets = self._split(subsets)
                 complement_offset = (complement_offset * len(next_subsets)) / len(subsets)
@@ -85,8 +105,9 @@ class AbstractDD(object):
 
             else:
                 # Minimization ends if no interesting configuration was found by the finest splitting.
+                logger.info("\t Final result: %d/%d" % (len(flatten(subsets)), len(self.original_config)))
                 logger.info('\tDone')
-                return config
+                return self.idx2config(current_config_idx)
 
     def _reduce_config(self, run, subsets, complement_offset):
         """
@@ -117,7 +138,7 @@ class AbstractDD(object):
 
         return cached_result
 
-    def _test_config(self, config, config_id):
+    def _test_config(self, config_idx, config_unique_id):
         """
         Test a single configuration and save the result in cache.
 
@@ -126,14 +147,17 @@ class AbstractDD(object):
             identifiable directories.
         :return: PASS or FAIL
         """
-        config_id = self._id_prefix + config_id
+        config_unique_id = self._id_prefix + config_unique_id
 
-        logger.debug('\t[ %s ]: test...', self._pretty_config_id(config_id))
-        outcome = self._test(config, config_id)
-        logger.debug('\t[ %s ]: test = %r', self._pretty_config_id(config_id), outcome)
+        logger.debug('\t[ %s ]: test...', self._pretty_config_id(config_unique_id))
+        tstart = time.time()
+        config = self.idx2config(config_idx)
+        outcome = self._test(config, config_unique_id)
+        logger.info("execution time of this test: " + str(time.time() - tstart) + "s")
+        logger.debug('\t[ %s ]: test = %r', self._pretty_config_id(config_unique_id), outcome)
 
-        if 'assert' not in config_id:
-            self._cache.add(config, outcome)
+        if 'assert' not in config_unique_id:
+            self._cache.add(config_idx, outcome)
 
         return outcome
 
@@ -152,3 +176,11 @@ class AbstractDD(object):
         :return: Concatenating the arguments with slashes, e.g., "rN / DM".
         """
         return ' / '.join(str(i) for i in config_id)
+    
+    def idx2config(self, indices):
+        new_indices = indices[:]
+        new_indices.sort()
+        config = []
+        for i in indices:
+            config.append(self.original_config[i])
+        return config
diff --git a/src/picire/picire/abstract_fastdd.py b/src/picire/picire/abstract_fastdd.py
new file mode 100644
index 00000000..c3d55a88
--- /dev/null
+++ b/src/picire/picire/abstract_fastdd.py
@@ -0,0 +1,228 @@
+# Copyright (c) 2016-2020 Renata Hodovan, Akos Kiss.
+#
+# Licensed under the BSD 3-Clause License
+# <LICENSE.rst or https://opensource.org/licenses/BSD-3-Clause>.
+# This file may not be copied, modified, or distributed except
+# according to those terms.
+
+import logging
+import random
+import ast
+import collections
+import time
+import traceback
+from .outcome_cache import OutcomeCache, ContentCache
+import copy
+import os
+import uuid
+from collections import defaultdict
+
+logger = logging.getLogger(__name__)
+random_filename = "%s.txt" % uuid.uuid4()
+
+def divide_by_two(num):
+    results = []
+    while num > 1:
+        num = num // 2
+        results.append(num)
+    return results
+
+def compute_recommended_size():
+    if (not os.path.exists(random_filename)):
+        return None
+    size_success_counts = defaultdict(int)
+    size_total_counts = defaultdict(int)
+
+    with open(random_filename, 'r') as f:
+        lines = f.readlines()
+        for line in lines:
+            size, state = line.strip().split(':')
+            size = int(size)
+            size_total_counts[size] += 1
+            if state == 'success':
+                size_success_counts[size] += 1
+    if (len(lines) < 100):
+        return None
+    size_success_rates = {}
+    for size, total_count in size_total_counts.items():
+        success_rate = 1.0 * size_success_counts[size] / total_count
+        size_success_rates[size] = success_rate
+
+    sorted_sizes = sorted(size_success_rates.items(), key=lambda x: x[1], reverse=True)
+
+    normalized_success_expectation = []
+    total_success_expectation = sum([size * rate for size, rate in sorted_sizes])
+    
+    accumulated_success_expectation = 0
+    selected_sizes = []
+    for size, success_expectation in sorted_sizes:
+        normalized_success_expectation = success_expectation / total_success_expectation
+        accumulated_success_expectation += normalized_success_expectation
+        selected_sizes.append(size)
+        if accumulated_success_expectation >= 0.95:
+            break
+
+    return selected_sizes
+
+def update_file(size, state):
+    with open(random_filename, "a") as f:
+        f.write("%d:%s\n" % (size, state))
+
+class AbstractFastDD(object):
+    """
+    Abstract super-class of the parallel and non-parallel DD classes.
+    """
+
+    # Test outcomes.
+    PASS = 'PASS'
+    FAIL = 'FAIL'
+
+    def __init__(self, test, split, cache=None, id_prefix=(), onepass=False):
+        """
+        Initialise an abstract DD class. Not to be called directly, only by
+        super calls in subclass initializers.
+        :param test: A callable tester object.
+        :param split: Splitter method to break a configuration up to n parts.
+        :param cache: Cache object to use.
+        :param id_prefix: Tuple to prepend to config IDs during tests.
+        """
+        self._test = test
+        self._split = split
+        self._cache = cache or OutcomeCache()
+        self._id_prefix = id_prefix
+        self.p = collections.OrderedDict()
+        self.memory = {}
+        self.testHistory = []
+        self.passconfig = []
+        logger.info(random_filename)
+
+    def __call__(self, config):
+        """
+        Return a 1-minimal failing subset of the initial configuration.
+        :param config: The initial configuration that will be reduced.
+        :return: 1-minimal failing configuration.
+        """
+        tstart = time.time()
+        self.original_config = config[:]
+        self.original_config_id = list(range(len(config)))
+        run = 0
+        self.passconfig = self.original_config
+        partition_size_list = compute_recommended_size()
+        if (partition_size_list is None):
+            partition_size_list = divide_by_two(len(self.passconfig))
+
+        for partition_size in partition_size_list:
+            if (partition_size > len(self.passconfig)):
+                continue
+            idx = 0
+            while (idx + partition_size <= len(self.passconfig)):
+                logger.info('Run #%d', run)
+                run = run + 1
+                config_id = ('r%d' % run, )
+                logger.info('\tConfig size: %d' % len(self.passconfig))
+                logger.info("\tSelected deletion size: %d" % partition_size)
+                config2test = self.passconfig[0:idx] + self.passconfig[idx+partition_size:]
+                deleted_config = self.passconfig[idx:idx+partition_size]
+                self.printIdx(deleted_config, "Try deleting")
+                outcome = self._test_config(config2test,config_id)
+                if outcome == self.FAIL:
+                    idx = idx + partition_size
+                    update_file(partition_size, "fail")
+                else:
+                    self.printIdx(deleted_config, "Deleted")
+                    self.passconfig = config2test
+                    update_file(partition_size, "success")
+        
+        logger.info("Final size: %d/%d" % (len(self.passconfig), len(config)))
+        logger.info("Execution time at this level: %f s" % (time.time() - tstart))
+        return self.passconfig
+            
+    def printIdx(self, deleteconfig, info):
+        indices = []
+        for item in deleteconfig:
+            idx = self.original_config.index(item)
+            indices.append(idx)
+        indices.sort()
+        logger.info("\t%s: %r" % (info, indices))
+
+    def _processElementToPreserve(toBePreserve):
+        raise NotImplementedError()
+
+    def _process(self, config, outcome):
+        raise NotImplementedError()
+
+    def _lookup_history(self, config):
+        if self.memory.has_key(str(config)):
+            return self.memory[str(config)]
+        return None
+
+    def _lookup_cache(self, config, config_id):
+        """
+        Perform a cache lookup if caching is enabled.
+        :param config: The configuration we are looking for.
+        :param config_id: The ID describing the configuration (only for debug
+            message).
+        :return: None if outcome is not found for config in cache or if caching
+            is disabled, PASS or FAIL otherwise.
+        """
+        cached_result = self._cache.lookup(config)
+        if cached_result is not None:
+            logger.debug('\t[ %s ]: cache = %r', self._pretty_config_id(self._id_prefix + config_id), cached_result)
+
+        return cached_result
+
+    def _test_config(self, config, config_id):
+        """
+        Test a single configuration and save the result in cache.
+        :param config: The current configuration to test.
+        :param config_id: Unique ID that will be used to save tests to easily
+            identifiable directories.
+        :return: PASS or FAIL
+        """
+        config_id = self._id_prefix + config_id
+
+        logger.debug('\t[ %s ]: test...', self._pretty_config_id(config_id))
+        outcome = self._test(config, config_id)
+        logger.debug('\t[ %s ]: test = %r', self._pretty_config_id(config_id), outcome)
+
+        if 'assert' not in config_id:
+            self._cache.add(config, outcome)
+
+        return outcome
+
+    @staticmethod
+    def _pretty_config_id(config_id):
+        """
+        Create beautified identifier for the current task from the argument.
+        The argument is typically a tuple in the form of ('rN', 'DM'), where N
+        is the index of the current iteration, D is direction of reduce (either
+        s(ubset) or c(omplement)), and M is the index of the current test in the
+        iteration. Alternatively, argument can also be in the form of
+        (rN, 'assert') for double checking the input at the start of an
+        iteration.
+        :param config_id: Config ID tuple.
+        :return: Concatenating the arguments with slashes, e.g., "rN / DM".
+        """
+        return ' / '.join(str(i) for i in config_id)
+
+    @staticmethod
+    def _minus(c1, c2):
+        """
+        Return a list of all elements of C1 that are not in C2.
+        """
+        c2 = set(c2)
+        return [c for c in c1 if c not in c2]
+    
+    @staticmethod
+    def _aInb(c1,c2):
+        for i in c1:
+            if i not in c2:
+                return False
+        return True
+
+    @staticmethod
+    def _intersect(c1,c2):
+        for i in c1:
+            if i in c2:
+                return True
+        return False
diff --git a/src/picire/picire/abstract_simplifiedprobdd.py b/src/picire/picire/abstract_simplifiedprobdd.py
new file mode 100644
index 00000000..e94a39d8
--- /dev/null
+++ b/src/picire/picire/abstract_simplifiedprobdd.py
@@ -0,0 +1,170 @@
+# Copyright (c) 2016-2020 Renata Hodovan, Akos Kiss.
+#
+# Licensed under the BSD 3-Clause License
+# <LICENSE.rst or https://opensource.org/licenses/BSD-3-Clause>.
+# This file may not be copied, modified, or distributed except
+# according to those terms.
+
+import logging
+import random
+import ast
+import collections
+import time
+import traceback
+from .outcome_cache import OutcomeCache, ContentCache
+import copy
+logger = logging.getLogger(__name__)
+
+
+class AbstractSimplifiedProbDD(object):
+    """
+    Abstract super-class of the parallel and non-parallel DD classes.
+    """
+
+    # Test outcomes.
+    PASS = 'PASS'
+    FAIL = 'FAIL'
+
+    def __init__(self, test, split, cache=None, id_prefix=()):
+        """
+        Initialise an abstract DD class. Not to be called directly, only by
+        super calls in subclass initializers.
+        :param test: A callable tester object.
+        :param split: Splitter method to break a configuration up to n parts.
+        :param cache: Cache object to use.
+        :param id_prefix: Tuple to prepend to config IDs during tests.
+        """
+        self._test = test
+        self._split = split
+        self._cache = cache or OutcomeCache()
+        self._id_prefix = id_prefix
+        self.p = collections.OrderedDict()
+        self.memory = {}
+        self.testHistory = []
+        self.passconfig = []
+
+    def __call__(self, config):
+        """
+        Return a 1-minimal failing subset of the initial configuration.
+        :param config: The initial configuration that will be reduced.
+        :return: 1-minimal failing configuration.
+        """
+        tstart = time.time()
+        self.original_config = config[:]
+        self.original_config_id = list(range(len(config)))
+        run = 0
+        self.passconfig = self.original_config
+        partition_size_list = [9, 5, 3, 1]
+        for partition_size in partition_size_list:
+            if (partition_size > len(self.passconfig)):
+                continue
+            idx = 0
+            while (idx + partition_size <= len(self.passconfig)):
+                logger.info('Run #%d', run)
+                run = run + 1
+                config_id = ('r%d' % run, )
+                logger.info('\tConfig size: %d' % len(self.passconfig))
+                logger.info("\tSelected deletion size: %d" % partition_size)
+                config2test = self.passconfig[0:idx] + self.passconfig[idx+partition_size:]
+                deleted_config = self.passconfig[idx:idx+partition_size]
+                self.printIdx(deleted_config, "Try deleting")
+                outcome = self._test_config(config2test,config_id)
+                if outcome == self.FAIL:
+                    idx = idx + partition_size
+                else:
+                    self.printIdx(deleted_config, "Deleted")
+                    self.passconfig = config2test
+        
+        logger.info("Final size: %d/%d" % (len(self.passconfig), len(config)))
+        logger.info("Execution time at this level: %f s" % (time.time() - tstart))
+        return self.passconfig
+            
+    def printIdx(self, deleteconfig, info):
+        indices = []
+        for item in deleteconfig:
+            idx = self.original_config.index(item)
+            indices.append(idx)
+        indices.sort()
+        logger.info("\t%s: %r" % (info, indices))
+
+    def _processElementToPreserve(toBePreserve):
+        raise NotImplementedError()
+
+    def _process(self, config, outcome):
+        raise NotImplementedError()
+
+    def _lookup_history(self, config):
+        if self.memory.has_key(str(config)):
+            return self.memory[str(config)]
+        return None
+
+    def _lookup_cache(self, config, config_id):
+        """
+        Perform a cache lookup if caching is enabled.
+        :param config: The configuration we are looking for.
+        :param config_id: The ID describing the configuration (only for debug
+            message).
+        :return: None if outcome is not found for config in cache or if caching
+            is disabled, PASS or FAIL otherwise.
+        """
+        cached_result = self._cache.lookup(config)
+        if cached_result is not None:
+            logger.debug('\t[ %s ]: cache = %r', self._pretty_config_id(self._id_prefix + config_id), cached_result)
+
+        return cached_result
+
+    def _test_config(self, config, config_id):
+        """
+        Test a single configuration and save the result in cache.
+        :param config: The current configuration to test.
+        :param config_id: Unique ID that will be used to save tests to easily
+            identifiable directories.
+        :return: PASS or FAIL
+        """
+        config_id = self._id_prefix + config_id
+
+        logger.debug('\t[ %s ]: test...', self._pretty_config_id(config_id))
+        outcome = self._test(config, config_id)
+        logger.debug('\t[ %s ]: test = %r', self._pretty_config_id(config_id), outcome)
+
+        if 'assert' not in config_id:
+            self._cache.add(config, outcome)
+
+        return outcome
+
+    @staticmethod
+    def _pretty_config_id(config_id):
+        """
+        Create beautified identifier for the current task from the argument.
+        The argument is typically a tuple in the form of ('rN', 'DM'), where N
+        is the index of the current iteration, D is direction of reduce (either
+        s(ubset) or c(omplement)), and M is the index of the current test in the
+        iteration. Alternatively, argument can also be in the form of
+        (rN, 'assert') for double checking the input at the start of an
+        iteration.
+        :param config_id: Config ID tuple.
+        :return: Concatenating the arguments with slashes, e.g., "rN / DM".
+        """
+        return ' / '.join(str(i) for i in config_id)
+
+    @staticmethod
+    def _minus(c1, c2):
+        """
+        Return a list of all elements of C1 that are not in C2.
+        """
+        c2 = set(c2)
+        return [c for c in c1 if c not in c2]
+    
+    @staticmethod
+    def _aInb(c1,c2):
+        for i in c1:
+            if i not in c2:
+                return False
+        return True
+
+    @staticmethod
+    def _intersect(c1,c2):
+        for i in c1:
+            if i in c2:
+                return True
+        return False
diff --git a/src/picire/picire/cdd.py b/src/picire/picire/cdd.py
new file mode 100644
index 00000000..015771b1
--- /dev/null
+++ b/src/picire/picire/cdd.py
@@ -0,0 +1,66 @@
+# Copyright (c) 2016-2019 Renata Hodovan, Akos Kiss.
+#
+# Licensed under the BSD 3-Clause License
+# <LICENSE.rst or https://opensource.org/licenses/BSD-3-Clause>.
+# This file may not be copied, modified, or distributed except
+# according to those terms.
+
+import logging
+
+from . import config_iterators
+from . import config_splitters
+from .abstract_cdd import AbstractCDD
+
+logger = logging.getLogger(__name__)
+
+
+class CDD(AbstractCDD):
+
+    def __init__(self, test, cache=None, id_prefix=(), 
+                 split=config_splitters.zeller,
+                 subset_first=True, subset_iterator=config_iterators.forward,
+                 complement_iterator=config_iterators.forward, **other_config):
+        """
+        Initialize a ProbDD object.
+        :param test: A callable tester object.
+        :param cache: Cache object to use.
+        :param id_prefix: Tuple to prepend to config IDs during tests.
+        :param split: Splitter method to break a configuration up to n parts.
+        :param subset_first: Boolean value denoting whether the reduce has to
+            start with the subset-based approach or not.
+        :param subset_iterator: Reference to a generator function that provides
+            config indices in an arbitrary order.
+        :param complement_iterator: Reference to a generator function that
+            provides config indices in an arbitrary order.
+        """
+        AbstractCDD.__init__(self, test, split, id_prefix=id_prefix, other_config=other_config)
+
+    def _processElementToPreserve(self,toBePreserve):
+        tmp = []
+        for history in self.testHistory:
+            if self._intersect(toBePreserve, history):
+                cha = self._minus(history, toBePreserve)
+            else:
+                tmp.append(history)
+        self.testHistory = tmp
+        for elm in toBePreserve:
+            self.counter[elm] = -1
+
+    def _process(self,config,outcome):
+        tmp=[]
+        toBePreserve=[]
+        if outcome==self.PASS:
+            for history in self.testHistory:
+                if self._intersect(config,history):
+                    cha=self._minus(history,config)
+                    if len(cha)==1:
+                        if not(cha[0] in toBePreserve):
+                            toBePreserve.append(cha[0])
+                    else:
+                        tmp.append(cha)
+                else:
+                    tmp.append(history)
+            self.testHistory=tmp
+            self._processElementToPreserve(toBePreserve)
+        elif outcome==self.FAIL:
+            self._processElementToPreserve(config)
diff --git a/src/picire/picire/cli.py b/src/picire/picire/cli.py
index 1b675d81..9cfc1e8a 100644
--- a/src/picire/picire/cli.py
+++ b/src/picire/picire/cli.py
@@ -22,6 +22,9 @@ from . import logging
 from .combined_iterator import CombinedIterator
 from .combined_parallel_dd import CombinedParallelDD
 from .light_dd import LightDD
+from .cdd import CDD
+from .simplifiedprob_dd import SimplifiedProbDD
+from .fast_dd import FastDD
 from .parallel_dd import ParallelDD
 from .shared_cache import shared_cache_decorator
 from .subprocess_test import ConcatTestBuilder, SubprocessTest
@@ -45,7 +48,7 @@ def create_parser():
 
     # Base reduce settings.
     parser.add_argument('--cache', metavar='NAME',
-                        choices=[i for i in dir(outcome_cache) if not i.startswith('_') and i.islower()], default='config',
+                        choices=[i for i in dir(outcome_cache) if not i.startswith('_') and i.islower()], default='none',
                         help='cache strategy (%(choices)s; default: %(default)s)')
     parser.add_argument('--split', metavar='NAME',
                         choices=[i for i in dir(config_splitters) if not i.startswith('_') and i.islower()], default='zeller',
@@ -89,6 +92,14 @@ def create_parser():
                         help='working directory (default: input.timestamp)')
     parser.add_argument('--disable-cleanup', dest='cleanup', default=True, action='store_false',
                         help='disable the removal of generated temporary files')
+    
+     # Ddmin settings
+    parser.add_argument('--dd', metavar='NAME', choices=['ddmin', 'probdd', 'fastdd', 'simplifiedprobdd', 'cdd'], default='ddmin',
+                            help='DD variant to run (%(choices)s; default: %(default)s)')
+    parser.add_argument('--onepass', default=False, action='store_true', help='do not reset index to 0 when a partition is deleted')
+    parser.add_argument('--id', metavar='NUMBER', type=int, default=0, help='just used for identify each trail')
+    parser.add_argument('--start-from-n', metavar='NUMBER', type=int, default=None, help='partition size start from a specified number, instead of half of the total size')
+    parser.add_argument('--init-probability', metavar='NUMBER', type=float, default=0.1, help='provide the initial probability for probdd, default value is 0.1')
     return parser
 
 
@@ -108,10 +119,7 @@ def process_args(parser, args):
         except LookupError:
             parser.error('The given encoding (%s) is not known.' % args.encoding)
     else:
-        args.encoding = chardet.detect(args.src)['encoding']
-        if not args.encoding:
-            parser.error('The encoding of the test case is not recognized. '
-                         'Please define it with the --encoding command line option.')
+        args.encoding = chardet.detect(args.src)['encoding'] or 'latin-1'
 
     args.test = realpath(args.test)
     if not exists(args.test) or not os.access(args.test, os.X_OK):
@@ -120,7 +128,7 @@ def process_args(parser, args):
     args.tester_class = SubprocessTest
     args.tester_config = {
         'encoding': args.encoding,
-        'command_pattern': '%s %%s' % args.test,
+        'command_pattern': [args.test, '%s'],
         'cleanup': args.cleanup,
     }
 
@@ -135,7 +143,15 @@ def process_args(parser, args):
     # Choose the reducer class that will be used and its configuration.
     args.reduce_config = {'split': split_class(n=args.granularity)}
     if not args.parallel:
-        args.reduce_class = LightDD
+        if (args.dd == 'probdd' or args.dd == 'cdd'):
+            args.reduce_class = CDD
+        elif (args.dd == 'ddmin'):
+            args.reduce_class = LightDD
+        elif (args.dd == 'fastdd'):
+            args.reduce_class = FastDD
+        elif (args.dd == 'simplifiedprobdd'):
+            args.reduce_class = SimplifiedProbDD
+        
         args.reduce_config['subset_iterator'] = subset_iterator
         args.reduce_config['complement_iterator'] = complement_iterator
         args.reduce_config['subset_first'] = args.subset_first
@@ -154,6 +170,13 @@ def process_args(parser, args):
             args.reduce_config['complement_iterator'] = complement_iterator
             args.reduce_config['subset_first'] = args.subset_first
 
+    # configs about probdd and cdd
+    args.reduce_config['onepass'] = args.onepass
+    args.reduce_config['start_from_n'] = args.start_from_n
+    args.reduce_config['init_probability'] = args.init_probability
+    args.reduce_config['id'] = args.id
+    args.reduce_config['dd'] = args.dd
+
     args.out = realpath(args.out if args.out else '%s.%s' % (args.input, time.strftime('%Y%m%d_%H%M%S')))
 
 
@@ -174,10 +197,20 @@ def log_args(title, args):
                     log += ['%s: %s' % (k_log, v_log)]
             return log if len(log) > 1 else log[0]
         if isinstance(args, list):
-            return ', '.join(_log_args(v) for v in args)
+            v_logs = [_log_args(v) for v in args]
+            if any(isinstance(v_log, list) for v_log in v_logs):
+                log = []
+                for v_log in v_logs:
+                    if not isinstance(v_log, list):
+                        v_log = [v_log]
+                    for i, line in enumerate(v_log):
+                        log += ['%s %s' % ('-' if i == 0 else ' ', line)]
+            else:
+                log = ', '.join(v_log for v_log in v_logs)
+            return log
         if hasattr(args, '__name__'):
             return '.'.join(([args.__module__] if hasattr(args, '__module__') else []) + [args.__name__])
-        return args
+        return str(args)
     logger.info('%s\n\t%s\n', title, '\n\t'.join(_log_args(args)))
 
 
@@ -240,7 +273,7 @@ def call(reduce_class, reduce_config,
                                    **tester_config),
                       cache=cache,
                       **reduce_config)
-    min_set = dd.ddmin(list(range(len(content))))
+    min_set = dd(list(range(len(content))))
 
     logger.trace('The cached results are: %s', cache)
     logger.debug('A minimal config is: %r', min_set)
@@ -276,11 +309,13 @@ def execute():
     parser.add_argument('--version', action='version', version='%(prog)s {version}'.format(version=__version__))
 
     args = parser.parse_args()
+    print(args)
     process_args(parser, args)
 
     logging.basicConfig(format='%(message)s')
     logger.setLevel(args.log_level)
 
+    tstart = time.time()
     call(reduce_class=args.reduce_class,
          reduce_config=args.reduce_config,
          tester_class=args.tester_class,
@@ -291,4 +326,6 @@ def execute():
          out=args.out,
          atom=args.atom,
          cache_class=args.cache,
-         cleanup=args.cleanup)
+         cleanup=args.cleanup,
+         )
+    print("execution time: " + str(time.time() - tstart) + "s")
\ No newline at end of file
diff --git a/src/picire/picire/config_iterators.py b/src/picire/picire/config_iterators.py
index 76d19072..838bc62b 100644
--- a/src/picire/picire/config_iterators.py
+++ b/src/picire/picire/config_iterators.py
@@ -5,9 +5,34 @@
 # This file may not be copied, modified, or distributed except
 # according to those terms.
 
-forward = range  #: Generator returning numbers from 0 to n-1.
+class ResetableIterator:
+    def __init__(self, list):
+        self.list = list
+        self.num = len(list)
+        self.idx = 0
+    def __iter__(self):
+        return self
+    def __next__(self):
+        if self.idx >= self.num:
+            raise StopIteration
+        idx = self.idx
+        self.idx += 1
+        return self.list[idx]
+    def reset(self):
+      self.idx = 0
 
 
+def forward(n):
+    """
+    Generator returning numbers from 0 to n - 1 increasing by 1.
+
+    :param n: Upper bound of the interval.
+    :return: Increasing numbers from 0 to n - 1.
+    """
+    l = list(range(n))
+    iterator = ResetableIterator(l)
+    return iterator
+
 def backward(n):
     """
     Generator returning numbers from n - 1 to 0 decreasing by 1.
@@ -15,8 +40,9 @@ def backward(n):
     :param n: Upper bound of the interval.
     :return: Decreasing numbers from n - 1 to 0.
     """
-    for i in range(n - 1, -1, -1):
-        yield i
+    l = list(range(n - 1, -1, -1))
+    iterator = ResetableIterator(l)
+    return iterator
 
 
 def skip(n):
@@ -28,8 +54,9 @@ def skip(n):
         reasons.
     :return: None
     """
-    for i in ():
-        yield i
+    l = list(range(0))
+    iterator = ResetableIterator(l)
+    return iterator
 
 
 def random(n):
@@ -43,5 +70,5 @@ def random(n):
 
     lst = list(range(n))
     shuffle(lst)
-    for i in lst:
-        yield i
+    iterator = ResetableIterator(lst)
+    return iterator
diff --git a/src/picire/picire/fast_dd.py b/src/picire/picire/fast_dd.py
new file mode 100644
index 00000000..c5a145ff
--- /dev/null
+++ b/src/picire/picire/fast_dd.py
@@ -0,0 +1,68 @@
+# Copyright (c) 2016-2019 Renata Hodovan, Akos Kiss.
+#
+# Licensed under the BSD 3-Clause License
+# <LICENSE.rst or https://opensource.org/licenses/BSD-3-Clause>.
+# This file may not be copied, modified, or distributed except
+# according to those terms.
+
+import logging
+
+from . import config_iterators
+from . import config_splitters
+from .abstract_fastdd import AbstractFastDD
+from .outcome_cache import ConfigCache
+
+logger = logging.getLogger(__name__)
+
+
+class FastDD(AbstractFastDD):
+
+    def __init__(self, test, cache=None, id_prefix=(), onepass=False, start_from_n=None,
+                 split=config_splitters.zeller,
+            subset_first=True, subset_iterator=config_iterators.forward, 
+            complement_iterator=config_iterators.forward):
+        """
+        Initialize a ProbDD object.
+        :param test: A callable tester object.
+        :param cache: Cache object to use.
+        :param id_prefix: Tuple to prepend to config IDs during tests.
+        :param split: Splitter method to break a configuration up to n parts.
+        :param subset_first: Boolean value denoting whether the reduce has to
+            start with the subset-based approach or not.
+        :param subset_iterator: Reference to a generator function that provides
+            config indices in an arbitrary order.
+        :param complement_iterator: Reference to a generator function that
+            provides config indices in an arbitrary order.
+        """
+        cache = cache or ConfigCache()
+        AbstractFastDD.__init__(self, test, split, cache=cache, id_prefix=id_prefix)
+
+    def _processElementToPreserve(self,toBePreserve):
+        tmp = []
+        for history in self.testHistory:
+            if self._intersect(toBePreserve, history):
+                cha = self._minus(history, toBePreserve)
+            else:
+                tmp.append(history)
+        self.testHistory = tmp
+        for elm in toBePreserve:
+            self.p[elm] = 1
+
+    def _process(self,config,outcome):
+        tmp=[]
+        toBePreserve=[]
+        if outcome==self.PASS:
+            for history in self.testHistory:
+                if self._intersect(config,history):
+                    cha=self._minus(history,config)
+                    if len(cha)==1:
+                        if not(cha[0] in toBePreserve):
+                            toBePreserve.append(cha[0])
+                    else:
+                        tmp.append(cha)
+                else:
+                    tmp.append(history)
+            self.testHistory=tmp
+            self._processElementToPreserve(toBePreserve)
+        elif outcome==self.FAIL:
+            self._processElementToPreserve(config)
diff --git a/src/picire/picire/light_dd.py b/src/picire/picire/light_dd.py
index 38417085..3a28ac52 100644
--- a/src/picire/picire/light_dd.py
+++ b/src/picire/picire/light_dd.py
@@ -10,7 +10,7 @@ import logging
 from . import config_iterators
 from . import config_splitters
 from .abstract_dd import AbstractDD
-from .outcome_cache import ConfigCache
+from . import utils
 
 logger = logging.getLogger(__name__)
 
@@ -20,8 +20,9 @@ class LightDD(AbstractDD):
     Single process version of the Delta Debugging algorithm.
     """
 
-    def __init__(self, test, cache=None, id_prefix=(), split=config_splitters.zeller,
-                 subset_first=True, subset_iterator=config_iterators.forward, complement_iterator=config_iterators.forward):
+    def __init__(self, test, cache=None, id_prefix=(),
+                 split=config_splitters.zeller,
+                 subset_first=True, subset_iterator=config_iterators.forward, complement_iterator=config_iterators.forward, **other_config):
         """
         Initialize a LightDD object.
 
@@ -36,8 +37,9 @@ class LightDD(AbstractDD):
         :param complement_iterator: Reference to a generator function that
             provides config indices in an arbitrary order.
         """
-        cache = cache or ConfigCache()
-        AbstractDD.__init__(self, test, split, cache=cache, id_prefix=id_prefix)
+        cache = None
+
+        AbstractDD.__init__(self, test, split, cache=cache, id_prefix=id_prefix, other_config=other_config)
 
         self._subset_iterator = subset_iterator
         self._complement_iterator = complement_iterator
@@ -81,12 +83,22 @@ class LightDD(AbstractDD):
                 continue
 
             config_id = ('r%d' % run, 's%d' % i)
+            complement = [c for si, s in enumerate(subsets) for c in s if si != i]
             subset = subsets[i]
-
-            # Get the outcome either from cache or by testing it.
-            outcome = self._lookup_cache(subset, config_id) or self._test_config(subset, config_id)
-            if outcome == self.FAIL:
+            if (self.onepass):
+                if (complement in self.delete_history):
+                    continue
+                else:
+                    self.delete_history.append(subsets[i])
+            log_to_print = utils.generate_log(subsets[i], "Try deleting(complement of)", print_idx=True, threshold=30)
+            logger.info(log_to_print)
+
+            # Get the outcome by testing it.
+            outcome = self._test_config(subset, config_id)
+            if outcome == self.PASS:
                 # Interesting subset is found.
+                log_to_print = utils.generate_log(subsets[i], "Deleted(complement of)", print_idx=True, threshold=30)
+                logger.info(log_to_print)
                 return [subsets[i]], 0
 
         return None, complement_offset
@@ -103,18 +115,30 @@ class LightDD(AbstractDD):
             next complement_offset).
         """
         n = len(subsets)
-        for i in self._complement_iterator(n):
+        iterator = self._complement_iterator(n)
+        for i in iterator:
             if i is None:
                 continue
             i = int((i + complement_offset) % n)
 
             config_id = ('r%d' % run, 'c%d' % i)
             complement = [c for si, s in enumerate(subsets) for c in s if si != i]
-
-            outcome = self._lookup_cache(complement, config_id) or self._test_config(complement, config_id)
-            if outcome == self.FAIL:
+            if (self.onepass):
+                if (subsets[i] in self.delete_history):
+                    continue
+                else:
+                    self.delete_history.append(subsets[i])
+            log_to_print = utils.generate_log(subsets[i], "Try deleting", print_idx=True, threshold=30)
+            logger.info(log_to_print)
+
+            outcome = self._test_config(complement, config_id)
+            if outcome == self.PASS:
                 # Interesting complement is found.
                 # In next run, start removing the following subset
-                return subsets[:i] + subsets[i + 1:], i
+                log_to_print = utils.generate_log(subsets[i], "Deleted", print_idx=True, threshold=30)
+                logger.info(log_to_print)
+                iterator.reset()
+                return subsets[:i] + subsets[i + 1:], 0
 
         return None, complement_offset
+
diff --git a/src/picire/picire/logging.py b/src/picire/picire/logging.py
index 06768f99..0e81ebf2 100644
--- a/src/picire/picire/logging.py
+++ b/src/picire/picire/logging.py
@@ -8,6 +8,7 @@
 from __future__ import absolute_import
 
 from logging import *
+import sys
 
 
 TRACE = DEBUG // 2
@@ -30,5 +31,12 @@ __getLogger = getLogger
 
 def getLogger(name=None):
     logger = __getLogger(name)
+    logger.propagate = False
+    
+    handler = StreamHandler(sys.stdout)
+    formatter = Formatter('%(asctime)s - %(levelname)s - %(message)s')
+    handler.setFormatter(formatter)
+    logger.addHandler(handler)
+
     logger.trace = lambda msg, *args, **kwargs: logger.log(TRACE, msg, *args, **kwargs)
     return logger
diff --git a/src/picire/picire/parallel_dd.py b/src/picire/picire/parallel_dd.py
index c14648a2..f57cbd65 100644
--- a/src/picire/picire/parallel_dd.py
+++ b/src/picire/picire/parallel_dd.py
@@ -89,9 +89,9 @@ class ParallelDD(AbstractParallelDD):
 
             # If we had this test before, return the saved result.
             outcome = self._lookup_cache(subset, config_id)
-            if outcome == self.PASS:
-                continue
             if outcome == self.FAIL:
+                continue
+            if outcome == self.PASS:
                 self._fail_index.value = i
                 break
 
@@ -130,9 +130,9 @@ class ParallelDD(AbstractParallelDD):
 
             # If we had this test before, return its result
             outcome = self._lookup_cache(complement, config_id)
-            if outcome == self.PASS:
-                continue
             if outcome == self.FAIL:
+                continue
+            if outcome == self.PASS:
                 self._fail_index.value = i
                 break
 
diff --git a/src/picire/picire/simplifiedprob_dd.py b/src/picire/picire/simplifiedprob_dd.py
new file mode 100644
index 00000000..74a38441
--- /dev/null
+++ b/src/picire/picire/simplifiedprob_dd.py
@@ -0,0 +1,68 @@
+# Copyright (c) 2016-2019 Renata Hodovan, Akos Kiss.
+#
+# Licensed under the BSD 3-Clause License
+# <LICENSE.rst or https://opensource.org/licenses/BSD-3-Clause>.
+# This file may not be copied, modified, or distributed except
+# according to those terms.
+
+import logging
+
+from . import config_iterators
+from . import config_splitters
+from .abstract_simplifiedprobdd import AbstractSimplifiedProbDD
+from .outcome_cache import ConfigCache
+
+logger = logging.getLogger(__name__)
+
+
+class SimplifiedProbDD(AbstractSimplifiedProbDD):
+
+    def __init__(self, test, cache=None, id_prefix=(), onepass=False, start_from_n=None,
+                 split=config_splitters.zeller,
+                 subset_first=True, subset_iterator=config_iterators.forward, 
+                 complement_iterator=config_iterators.forward):
+        """
+        Initialize a SimplifiedProbDD object.
+        :param test: A callable tester object.
+        :param cache: Cache object to use.
+        :param id_prefix: Tuple to prepend to config IDs during tests.
+        :param split: Splitter method to break a configuration up to n parts.
+        :param subset_first: Boolean value denoting whether the reduce has to
+            start with the subset-based approach or not.
+        :param subset_iterator: Reference to a generator function that provides
+            config indices in an arbitrary order.
+        :param complement_iterator: Reference to a generator function that
+            provides config indices in an arbitrary order.
+        """
+        cache = cache or ConfigCache()
+        AbstractSimplifiedProbDD.__init__(self, test, split, cache=cache, id_prefix=id_prefix)
+
+    def _processElementToPreserve(self,toBePreserve):
+        tmp = []
+        for history in self.testHistory:
+            if self._intersect(toBePreserve, history):
+                cha = self._minus(history, toBePreserve)
+            else:
+                tmp.append(history)
+        self.testHistory = tmp
+        for elm in toBePreserve:
+            self.p[elm] = 1
+
+    def _process(self,config,outcome):
+        tmp=[]
+        toBePreserve=[]
+        if outcome==self.PASS:
+            for history in self.testHistory:
+                if self._intersect(config,history):
+                    cha=self._minus(history,config)
+                    if len(cha)==1:
+                        if not(cha[0] in toBePreserve):
+                            toBePreserve.append(cha[0])
+                    else:
+                        tmp.append(cha)
+                else:
+                    tmp.append(history)
+            self.testHistory=tmp
+            self._processElementToPreserve(toBePreserve)
+        elif outcome==self.FAIL:
+            self._processElementToPreserve(config)
diff --git a/src/picire/picire/subprocess_test.py b/src/picire/picire/subprocess_test.py
index 12e6efe9..a18fc48e 100644
--- a/src/picire/picire/subprocess_test.py
+++ b/src/picire/picire/subprocess_test.py
@@ -7,13 +7,12 @@
 
 import codecs
 import os
-import shlex
 import shutil
-import sys
 
 from subprocess import Popen
 
 from .abstract_dd import AbstractDD
+from .abstract_cdd import AbstractCDD
 
 
 class SubprocessTest(object):
@@ -23,8 +22,9 @@ class SubprocessTest(object):
         Wrapper around the script provided by the user. It decides about the
         interestingness based on the return code of executed script.
 
-        :param command_pattern: The command as the tester script should be ran.
-            Except that the path of the test is substituted with %s.
+        :param command_pattern: The tester command as a sequence of arguments.
+            If an element of the sequence contains %s, it is substituted with
+            the path to the test case.
         :param test_builder: Callable object that creates test case from a
             configuration.
         :param test_pattern: The patter of the test's path. It contains one %s
@@ -60,16 +60,23 @@ class SubprocessTest(object):
         with codecs.open(test_path, 'w', encoding=self.encoding, errors='ignore') as f:
             f.write(self.test_builder(config))
 
-        proc = Popen(shlex.split(self.command_pattern % test_path,
-                                 posix=not sys.platform.startswith('win32')),
-                     cwd=test_dir)
+        args = []
+        for arg in self.command_pattern:
+            try:
+                arg = arg % test_path
+            except TypeError:
+                pass
+            args.append(arg)
+        devnull = open(os.devnull, 'w')
+        proc = Popen(args, cwd=test_dir, stdout=devnull)
         proc.wait()
+        devnull.close()
 
         if self.cleanup:
             shutil.rmtree(test_dir)
 
         # Determine outcome.
-        return AbstractDD.FAIL if proc.returncode == 0 else AbstractDD.PASS
+        return AbstractCDD.PASS if proc.returncode == 0 else AbstractCDD.FAIL
 
 
 class ConcatTestBuilder(object):
diff --git a/src/picire/picire/utils.py b/src/picire/picire/utils.py
new file mode 100644
index 00000000..38a3e206
--- /dev/null
+++ b/src/picire/picire/utils.py
@@ -0,0 +1,13 @@
+def generate_log(config_idx, prefix="", print_idx=False, threshold=None):
+    config_idx.sort()
+    info_to_print = "\t%s " % prefix
+    info_to_print += "%d elements. " % len(config_idx)
+
+    if print_idx:
+        if threshold != None:
+            if len(config_idx) > threshold:
+                info_to_print += "Idx: %r ... %r" % (config_idx[:5], config_idx[-5:])
+            else:
+                info_to_print += "Idx: %r" % config_idx
+
+    return info_to_print
diff --git a/src/picire/setup.py b/src/picire/setup.py
index b8d972c3..f5e90222 100644
--- a/src/picire/setup.py
+++ b/src/picire/setup.py
@@ -6,23 +6,27 @@
 # according to those terms.
 
 from setuptools import find_packages, setup
-
+from os.path import dirname, join
+from setuptools import setup, find_packages
+import subprocess
 
 def picire_version():
-    def _version_scheme(version):
-        return version.format_with('{tag}')
+    with open(join(dirname(__file__), 'picire/VERSION'), 'rb') as f:
+        version = f.read().decode('ascii').strip()
+    return version
+
+def picire_detailed_version():
+    with open(join(dirname(__file__), 'picire/VERSION'), 'rb') as f:
+        version = f.read().decode('ascii').strip()
+        try:
+            git_version = subprocess.check_output(["git", "rev-parse", "--short", "HEAD"]).decode('ascii').strip()
+            if git_version:
+                version = f"{version}+{git_version}"
+        except subprocess.CalledProcessError:
+            pass
+    return version
 
-    def _local_scheme(version):
-        if version.exact and not version.dirty:
-            return ''
-        parts = ['{distance}'.format(distance=version.distance)]
-        if version.node:
-            parts.append('{node}'.format(node=version.node))
-        if version.dirty:
-            parts.append('d{time:%Y%m%d}'.format(time=version.time))
-        return '+{parts}'.format(parts='.'.join(parts))
 
-    return { 'version_scheme': _version_scheme, 'local_scheme': _local_scheme }
 
 
 setup(
@@ -38,8 +42,7 @@ setup(
     zip_safe=False,
     include_package_data=True,
     setup_requires=['setuptools_scm'],
-    #use_scm_version=picire_version,
-    version='20.12',
+    version=picire_detailed_version(),
     entry_points={
         'console_scripts': ['picire = picire.cli:execute']
     },
